{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from conditional_inference.base import ModelBase, ResultsBase\n",
    "from conditional_inference.stats import truncnorm, quantile_unbiased\n",
    "from conditional_inference.utils import compute_projection_quantile, compute_projection_rvs\n",
    "from conditional_inference.squ import SQU\n",
    "from conditional_inference.rqu import RQU\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set()\n",
    "\n",
    "x = np.array([3.3, 4.1, 4.2, 4.3, 6.2])\n",
    "cov = np.array([\n",
    "    [.01, 0, 0, 0, 0],\n",
    "    [0, .25, 0, 0, 0],\n",
    "    [0, 0, .05, 0, 0],\n",
    "    [0, 0, 0, .05, 0],\n",
    "    [0, 0, 0, 0, .05]\n",
    "])\n",
    "\n",
    "# x = np.arange(0, 6, 2)\n",
    "# cov = np.identity(3)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "df = pd.read_csv(\"../../mega-analysis/data/processed/effort_experiment.csv\")\n",
    "results = sm.OLS(df.y, pd.get_dummies(df.arm)).fit().get_robustcov_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(ModelBase):\n",
    "    def fit(self, marginal=True, **kwargs):\n",
    "        return MarginalResults(self, **kwargs) if marginal else SimultaneousResults(self, **kwargs)\n",
    "\n",
    "class RankerResultsBase(ResultsBase):\n",
    "    TWO_TAILED, LOWER_TAILED, UPPER_TAILED = (\"two\", \"lower\", \"upper\")\n",
    "\n",
    "    @property\n",
    "    def tails(self):\n",
    "        return self._tails if hasattr(self, \"_tails\") else self.TWO_TAILED\n",
    "\n",
    "    @tails.setter\n",
    "    def tails(self, tails):\n",
    "        self._tails = self._check_tails(tails)\n",
    "\n",
    "    def _check_tails(self, tails):\n",
    "        if tails is None:\n",
    "            return self.tails\n",
    "\n",
    "        if tails not in (None, self.TWO_TAILED, self.LOWER_TAILED, self.UPPER_TAILED):\n",
    "            raise ValueError(f\"tails must be one of {self.TWO_TAILED, self.LOWER_TAILED, self.UPPER_TAILED}, got {tails}.\")\n",
    "        \n",
    "        return tails\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_delta_mean(mean, i):\n",
    "        return np.delete(mean[i] - mean, i)\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_delta_cov(cov, i, j):\n",
    "        repeat_i = np.repeat(np.atleast_2d(cov[i]), cov.shape[0], axis=0)\n",
    "        repeat_j = np.repeat(np.atleast_2d(cov[j]), cov.shape[0], axis=0).T\n",
    "        delta_cov = cov[i, j] + cov - repeat_i - repeat_j\n",
    "        return np.delete(np.delete(delta_cov, i, axis=0), j, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _stepdown(mean, cov, rvs, alpha):\n",
    "        rejected, newly_rejected = np.full(len(mean), False), None\n",
    "        std_deviation = np.sqrt(cov.diagonal())\n",
    "        while newly_rejected is None or (newly_rejected.any() and (~rejected).any()):\n",
    "            projection_quantile = np.quantile(rvs[:, ~rejected].max(axis=1), 1 - alpha)\n",
    "            newly_rejected = (mean - projection_quantile * std_deviation > 0) & ~rejected\n",
    "            rejected = newly_rejected | rejected\n",
    "\n",
    "        return rejected\n",
    "\n",
    "\n",
    "class MarginalResults(RankerResultsBase):\n",
    "    def __init__(self, model, *args, tails=\"two\", n_samples=10000, **kwargs):\n",
    "        super().__init__(model, *args, **kwargs)\n",
    "        mean = self.model.mean[self.indices]\n",
    "        cov = self.model.cov[self.indices][:, self.indices]\n",
    "        self.params = (-mean).argsort().argsort()\n",
    "        self.pvalues = np.full(self.n_policies, np.nan)\n",
    "        self.tails = tails\n",
    "\n",
    "        self.delta_mean, self.delta_cov, self.rvs = [], [], []\n",
    "        for i in range(self.n_policies):\n",
    "            delta_mean = self._compute_delta_mean(mean, i)\n",
    "            self.delta_mean.append(np.concatenate([delta_mean, -delta_mean]))\n",
    "            delta_cov = self._compute_delta_cov(cov, i, i)\n",
    "            delta_cov = np.vstack([\n",
    "                np.hstack([delta_cov, -delta_cov]),\n",
    "                np.hstack([-delta_cov, delta_cov])\n",
    "            ])\n",
    "            self.delta_cov.append(delta_cov)\n",
    "            rvs = multivariate_normal.rvs(np.zeros(delta_cov.shape[0]), delta_cov, size=n_samples)\n",
    "            self.rvs.append(rvs / np.sqrt(delta_cov.diagonal()))\n",
    "\n",
    "    def compute_hypothesis_matrix(self, alpha=.05, tails=None):\n",
    "        tails = self._check_tails(tails)\n",
    "        matrix = []\n",
    "        for i, (delta_mean, delta_cov, rvs) in enumerate(zip(self.delta_mean, self.delta_cov, self.rvs)):\n",
    "            if tails != self.TWO_TAILED:\n",
    "                # select the relevant objects for 1-tailed hypotheses\n",
    "                indices = slice(0, self.n_policies-1) if tails == self.LOWER_TAILED else slice(self.n_policies-1, 2*(self.n_policies-1))\n",
    "                delta_mean = delta_mean[indices]\n",
    "                delta_cov = delta_cov[indices, indices]\n",
    "                rvs = rvs[:, indices]\n",
    "\n",
    "            rejected = self._stepdown(delta_mean, delta_cov, rvs, alpha)[:self.n_policies-1]\n",
    "            rejected = np.insert(rejected, i, False)\n",
    "            matrix.append(rejected)\n",
    "\n",
    "        return pd.DataFrame(np.array(matrix).T, columns=self.model.exog_names, index=self.model.exog_names)\n",
    "\n",
    "    def conf_int(self, alpha=.05, tails=None):\n",
    "        tails = self._check_tails(tails)\n",
    "        conf_int = super().conf_int(alpha)\n",
    "        hypothesis_matrix = self.compute_hypothesis_matrix(alpha, tails)\n",
    "        conf_int = np.array([hypothesis_matrix.sum(1), ranker.n_policies - hypothesis_matrix.sum(0) - 1]).T\n",
    "        if tails == self.LOWER_TAILED:\n",
    "            conf_int[:, 0] = 0\n",
    "        elif tails == self.UPPER_TAILED:\n",
    "            conf_int[:, 0] = self.n_policies - conf_int[:, 1] - 1\n",
    "            conf_int[:, 1] = self.n_policies - 1\n",
    "        return conf_int\n",
    "\n",
    "\n",
    "# ranker = Ranker.from_csv(\"../../mega-analysis/data/conventional_estimates/penn_medicine.csv\").fit(cols=\"sorted\", marginal=True)\n",
    "# ranker = Ranker.from_results(results).fit(cols=\"sorted\", tails=\"lower\", marginal=True)\n",
    "ranker = Ranker(x, cov).fit(tails=\"two\", marginal=True)\n",
    "hypothesis_matrix = ranker.compute_hypothesis_matrix()\n",
    "hypothesis_matrix\n",
    "# ranker.point_plot(alpha=.2)\n",
    "# rvs.shape, rejected.shape\n",
    "# ranker[0].shape, ranker[1].shape, ranker[2].shape\n",
    "# ranker.point_plot(alpha=.2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.point_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "class SimultaneousResults(RankerResultsBase):\n",
    "    def __init__(self, model, *args, tails=None, n_samples=10000, **kwargs):\n",
    "        super().__init__(model, *args, **kwargs)\n",
    "        mean = model.mean[self.indices]\n",
    "        cov = model.cov[self.indices][:, self.indices]\n",
    "        self.params = (-mean).argsort().argsort()\n",
    "        self.pvalues = np.full(self.n_policies, np.nan)\n",
    "        self.tails = tails\n",
    "        \n",
    "        delta_mean, delta_cov = [], []\n",
    "        for i in range(self.n_policies):\n",
    "            delta_mean.append(self._compute_delta_mean(mean, i))\n",
    "            delta_cov.append(np.hstack([self._compute_delta_cov(cov, i, j) for j in range(self.n_policies)]))\n",
    "        self.delta_mean = np.concatenate(delta_mean)\n",
    "        self.delta_cov = np.vstack(delta_cov)\n",
    "        self.rvs = multivariate_normal.rvs(np.zeros(len(self.delta_mean)), self.delta_cov, size=n_samples)\n",
    "        self.rvs /= np.sqrt(self.delta_cov.diagonal())\n",
    "\n",
    "        # compute test statistics for the tau-best policies\n",
    "        # test_stats[tau, i] is the test statistic for policy i when computing policies with rank <= tau\n",
    "        arr = self.delta_mean / np.sqrt(self.delta_cov.diagonal())\n",
    "        arr = arr.reshape((self.n_policies, self.n_policies - 1))\n",
    "        arr = np.hstack((arr, np.zeros((self.n_policies, 1))))\n",
    "        arr.sort()\n",
    "        self.test_stats = -arr.T\n",
    "\n",
    "    def _get_mask(self, arr, get_mask_for_policy):\n",
    "        if isinstance(arr, int):\n",
    "            return get_mask_for_policy(arr)\n",
    "        elif len(arr) == 0:\n",
    "            return np.full(len(self.delta_mean), False)\n",
    "        return np.array([get_mask_for_policy(i) for i in arr]).any(axis=0)\n",
    "\n",
    "    def _get_i_minus_j_mask(self, arr):\n",
    "        def get_mask_for_policy(i):\n",
    "            indices = np.arange(i * (self.n_policies - 1), (i + 1) * (self.n_policies - 1))\n",
    "            mask = np.zeros(len(self.delta_mean))\n",
    "            mask[indices] = 1\n",
    "            return mask.astype(bool)\n",
    "\n",
    "        return self._get_mask(arr, get_mask_for_policy)\n",
    "\n",
    "    def _get_j_minus_i_mask(self, arr):\n",
    "        def get_mask_for_policy(i):\n",
    "            # delta_ji are the i-1'th indicies in groups before start and the i'th indicies in the groups after end\n",
    "            start, end = i * (self.n_policies - 1), (i + 1) * (self.n_policies - 1)\n",
    "            indices = np.concatenate((np.arange(i - 1, start, self.n_policies - 1), np.arange(end + i, len(self.delta_mean), self.n_policies - 1)))\n",
    "            if i == 0:\n",
    "                # indices will start with -1, which is incorrect\n",
    "                indices = indices[1:]\n",
    "            mask = np.zeros(len(self.delta_mean))\n",
    "            mask[indices] = 1\n",
    "            return mask.astype(bool)\n",
    "\n",
    "        return self._get_mask(arr, get_mask_for_policy)\n",
    "\n",
    "    def compute_best_policies(self, tau=0, alpha=.05, superset=True):\n",
    "        def compute_critical_value(subset):\n",
    "            k_mask = ~self._get_i_minus_j_mask(subset)\n",
    "            critical_value = np.quantile(self.rvs[:, k_mask & ~rejected_mask].max(axis=1), 1 - alpha)\n",
    "            return critical_value\n",
    "\n",
    "        if tau == self.n_policies - 1:\n",
    "            return np.full(self.n_policies, True)\n",
    "\n",
    "        if superset:\n",
    "            test_stats = self.test_stats[tau]\n",
    "        else:\n",
    "            test_stats = -self.test_stats[tau + 1]\n",
    "            tau = self.n_policies - tau - 1\n",
    "            \n",
    "        rejected, newly_rejected = np.full(self.n_policies, False), None\n",
    "        while newly_rejected is None or (newly_rejected.any() and (~rejected).any()):\n",
    "            rejected_mask = self._get_j_minus_i_mask(np.where(rejected)[0])\n",
    "            critical_value = max([compute_critical_value(i) for i in combinations(np.arange(self.n_policies), tau)])\n",
    "            newly_rejected = (test_stats > critical_value) & ~rejected\n",
    "            rejected = rejected | newly_rejected\n",
    "\n",
    "        return ~rejected if superset else rejected\n",
    "\n",
    "    def compute_hypothesis_matrix(self, alpha=.05):\n",
    "        matrix = []\n",
    "        rejected = self._stepdown(self.delta_mean, self.delta_cov, self.rvs, alpha)\n",
    "        for i in range(self.n_policies):\n",
    "            rejected_i = rejected[self._get_i_minus_j_mask(i)]\n",
    "            rejected_i = np.insert(rejected_i, i, False)\n",
    "            matrix.append(rejected_i)\n",
    "\n",
    "        return pd.DataFrame(np.array(matrix).T, columns=self.model.exog_names, index=self.model.exog_names)\n",
    "\n",
    "    def conf_int(self, alpha=.05):\n",
    "        hypothesis_matrix = self.compute_hypothesis_matrix(alpha)\n",
    "        return np.array([hypothesis_matrix.sum(1), ranker.n_policies - hypothesis_matrix.sum(0) - 1]).T\n",
    "\n",
    "ranker = Ranker(x, cov).fit(marginal=False)\n",
    "# ranker = Ranker.from_csv(\"../../mega-analysis/data/conventional_estimates/walmart.csv\").fit(cols=\"sorted\", marginal=False)\n",
    "# ranker = Ranker.from_results(results).fit(marginal=False)\n",
    "# ranker.compute_hypothesis_matrix()\n",
    "# x = 2 * np.arange(3)\n",
    "# cov = np.identity(3)\n",
    "# ranker = Ranker(x, cov).fit(cols=\"sorted\", marginal=False)\n",
    "# ranker._get_j_minus_i_indices(0)\n",
    "ranker.point_plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.compute_best_policies(tau=4, superset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.compute_hypothesis_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_policies = ranker.compute_best_policies(0, .5)\n",
    "best_policies, best_policies.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.delta_mean, ranker.delta_mean.reshape((ranker.n_policies, ranker.n_policies - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ranker.delta_mean / np.sqrt(ranker.delta_cov.diagonal())\n",
    "arr = arr.reshape((ranker.n_policies, ranker.n_policies - 1))\n",
    "arr = np.hstack((arr, np.zeros((ranker.n_policies, 1))))\n",
    "arr.sort()\n",
    "ranker.test_stats = -arr\n",
    "ranker.test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_tau(tau=0, alpha=.05):\n",
    "    def compute_critical_value(subset):\n",
    "        k_mask = ~ranker._get_i_minus_j_mask(subset)\n",
    "        critical_value = np.quantile(ranker.rvs[:, k_mask & ~rejected_mask].max(axis=1), 1 - alpha)\n",
    "        return critical_value\n",
    "\n",
    "    test_stats = ranker.test_stats[:, tau]\n",
    "    rejected, newly_rejected = np.full(ranker.n_policies, False), None\n",
    "    while newly_rejected is None or (newly_rejected.any() and (~rejected).any()):\n",
    "        rejected_mask = ranker._get_j_minus_i_mask(np.where(rejected)[0])\n",
    "        if tau == ranker.n_policies:\n",
    "            critical_value = 0\n",
    "        else:\n",
    "            critical_value = max([compute_critical_value(i) for i in combinations(np.arange(ranker.n_policies), tau)])\n",
    "        newly_rejected = (test_stats > critical_value) & ~rejected\n",
    "        rejected = rejected | newly_rejected\n",
    "\n",
    "    return rejected\n",
    "\n",
    "compute_best_tau(0, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "120d65e34230161c0f4356d19a77763cc2f6669dcb2a194d42d3b2faf517ecd2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
